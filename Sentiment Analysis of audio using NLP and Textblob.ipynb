{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Ashish\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Ashish\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"averaged_perceptron_tagger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob as blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = blob(\"hi, please like this video!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"hi, please like this video!\")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on TextBlob in module textblob.blob object:\n",
      "\n",
      "class TextBlob(BaseBlob)\n",
      " |  TextBlob(text, tokenizer=None, pos_tagger=None, np_extractor=None, analyzer=None, parser=None, classifier=None, clean_html=False)\n",
      " |  \n",
      " |  A general text block, meant for larger bodies of text (esp. those\n",
      " |  containing sentences). Inherits from :class:`BaseBlob <BaseBlob>`.\n",
      " |  \n",
      " |  :param str text: A string.\n",
      " |  :param tokenizer: (optional) A tokenizer instance. If ``None``, defaults to\n",
      " |      :class:`WordTokenizer() <textblob.tokenizers.WordTokenizer>`.\n",
      " |  :param np_extractor: (optional) An NPExtractor instance. If ``None``,\n",
      " |      defaults to :class:`FastNPExtractor() <textblob.en.np_extractors.FastNPExtractor>`.\n",
      " |  :param pos_tagger: (optional) A Tagger instance. If ``None``, defaults to\n",
      " |      :class:`NLTKTagger <textblob.en.taggers.NLTKTagger>`.\n",
      " |  :param analyzer: (optional) A sentiment analyzer. If ``None``, defaults to\n",
      " |      :class:`PatternAnalyzer <textblob.en.sentiments.PatternAnalyzer>`.\n",
      " |  :param classifier: (optional) A classifier.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      TextBlob\n",
      " |      BaseBlob\n",
      " |      textblob.mixins.StringlikeMixin\n",
      " |      textblob.mixins.BlobComparableMixin\n",
      " |      textblob.mixins.ComparableMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  sentences = <textblob.decorators.cached_property object>\n",
      " |  to_json(self, *args, **kwargs)\n",
      " |      Return a json representation (str) of this blob.\n",
      " |      Takes the same arguments as json.dumps.\n",
      " |      \n",
      " |      .. versionadded:: 0.5.1\n",
      " |  \n",
      " |  words = <textblob.decorators.cached_property object>\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  json\n",
      " |      The json representation of this blob.\n",
      " |      \n",
      " |      .. versionchanged:: 0.5.1\n",
      " |          Made ``json`` a property instead of a method to restore backwards\n",
      " |          compatibility that was broken after version 0.4.0.\n",
      " |  \n",
      " |  raw_sentences\n",
      " |      List of strings, the raw sentences in the blob.\n",
      " |  \n",
      " |  serialized\n",
      " |      Returns a list of each sentence's dict representation.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseBlob:\n",
      " |  \n",
      " |  __add__(self, other)\n",
      " |      Concatenates two text objects the same way Python strings are\n",
      " |      concatenated.\n",
      " |      \n",
      " |      Arguments:\n",
      " |      - `other`: a string or a text object\n",
      " |  \n",
      " |  __hash__(self)\n",
      " |      Return hash(self).\n",
      " |  \n",
      " |  __init__(self, text, tokenizer=None, pos_tagger=None, np_extractor=None, analyzer=None, parser=None, classifier=None, clean_html=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  classify(self)\n",
      " |      Classify the blob using the blob's ``classifier``.\n",
      " |  \n",
      " |  correct(self)\n",
      " |      Attempt to correct the spelling of a blob.\n",
      " |      \n",
      " |      .. versionadded:: 0.6.0\n",
      " |      \n",
      " |      :rtype: :class:`BaseBlob <BaseBlob>`\n",
      " |  \n",
      " |  detect_language(self)\n",
      " |      Detect the blob's language using the Google Translate API.\n",
      " |      \n",
      " |      Requires an internet connection.\n",
      " |      \n",
      " |      Usage:\n",
      " |      ::\n",
      " |      \n",
      " |          >>> b = TextBlob(\"bonjour\")\n",
      " |          >>> b.detect_language()\n",
      " |          u'fr'\n",
      " |      \n",
      " |      Language code reference:\n",
      " |          https://developers.google.com/translate/v2/using_rest#language-params\n",
      " |      \n",
      " |      .. versionadded:: 0.5.0\n",
      " |      \n",
      " |      :rtype: str\n",
      " |  \n",
      " |  ngrams(self, n=3)\n",
      " |      Return a list of n-grams (tuples of n successive words) for this\n",
      " |      blob.\n",
      " |      \n",
      " |      :rtype: List of :class:`WordLists <WordList>`\n",
      " |  \n",
      " |  noun_phrases = <textblob.decorators.cached_property object>\n",
      " |  np_counts = <textblob.decorators.cached_property object>\n",
      " |  parse(self, parser=None)\n",
      " |      Parse the text.\n",
      " |      \n",
      " |      :param parser: (optional) A parser instance. If ``None``, defaults to\n",
      " |          this blob's default parser.\n",
      " |      \n",
      " |      .. versionadded:: 0.6.0\n",
      " |  \n",
      " |  polarity = <textblob.decorators.cached_property object>\n",
      " |  pos_tags = <textblob.decorators.cached_property object>\n",
      " |  sentiment = <textblob.decorators.cached_property object>\n",
      " |  sentiment_assessments = <textblob.decorators.cached_property object>\n",
      " |  split(self, sep=None, maxsplit=9223372036854775807)\n",
      " |      Behaves like the built-in str.split() except returns a\n",
      " |      WordList.\n",
      " |      \n",
      " |      :rtype: :class:`WordList <WordList>`\n",
      " |  \n",
      " |  subjectivity = <textblob.decorators.cached_property object>\n",
      " |  tags = <textblob.decorators.cached_property object>\n",
      " |  tokenize(self, tokenizer=None)\n",
      " |      Return a list of tokens, using ``tokenizer``.\n",
      " |      \n",
      " |      :param tokenizer: (optional) A tokenizer object. If None, defaults to\n",
      " |          this blob's default tokenizer.\n",
      " |  \n",
      " |  tokens = <textblob.decorators.cached_property object>\n",
      " |  translate(self, from_lang='auto', to='en')\n",
      " |      Translate the blob to another language.\n",
      " |      Uses the Google Translate API. Returns a new TextBlob.\n",
      " |      \n",
      " |      Requires an internet connection.\n",
      " |      \n",
      " |      Usage:\n",
      " |      ::\n",
      " |      \n",
      " |          >>> b = TextBlob(\"Simple is better than complex\")\n",
      " |          >>> b.translate(to=\"es\")\n",
      " |          TextBlob('Lo simple es mejor que complejo')\n",
      " |      \n",
      " |      Language code reference:\n",
      " |          https://developers.google.com/translate/v2/using_rest#language-params\n",
      " |      \n",
      " |      .. versionadded:: 0.5.0.\n",
      " |      \n",
      " |      :param str from_lang: Language to translate from. If ``None``, will attempt\n",
      " |          to detect the language.\n",
      " |      :param str to: Language to translate to.\n",
      " |      :rtype: :class:`BaseBlob <BaseBlob>`\n",
      " |  \n",
      " |  word_counts = <textblob.decorators.cached_property object>\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from BaseBlob:\n",
      " |  \n",
      " |  analyzer = <textblob.en.sentiments.PatternAnalyzer object>\n",
      " |  \n",
      " |  np_extractor = <textblob.en.np_extractors.FastNPExtractor object>\n",
      " |  \n",
      " |  parser = <textblob.en.parsers.PatternParser object>\n",
      " |  \n",
      " |  pos_tagger = <textblob.en.taggers.NLTKTagger object>\n",
      " |  \n",
      " |  tokenizer = <textblob.tokenizers.WordTokenizer object>\n",
      " |  \n",
      " |  translator = <textblob.translate.Translator object>\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from textblob.mixins.StringlikeMixin:\n",
      " |  \n",
      " |  __contains__(self, sub)\n",
      " |      Implements the `in` keyword like a Python string.\n",
      " |  \n",
      " |  __getitem__(self, index)\n",
      " |      Returns a  substring. If index is an integer, returns a Python\n",
      " |      string of a single character. If a range is given, e.g. `blob[3:5]`,\n",
      " |      a new instance of the class is returned.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Makes the object iterable as if it were a string,\n",
      " |      iterating through the raw string's characters.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      Returns the length of the raw text.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Returns a string representation for debugging.\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Returns a string representation used in print statements\n",
      " |      or str(my_blob).\n",
      " |  \n",
      " |  ends_with = endswith(self, suffix, start=0, end=9223372036854775807)\n",
      " |  \n",
      " |  endswith(self, suffix, start=0, end=9223372036854775807)\n",
      " |      Returns True if the blob ends with the given suffix.\n",
      " |  \n",
      " |  find(self, sub, start=0, end=9223372036854775807)\n",
      " |      Behaves like the built-in str.find() method. Returns an integer,\n",
      " |      the index of the first occurrence of the substring argument sub in the\n",
      " |      sub-string given by [start:end].\n",
      " |  \n",
      " |  format(self, *args, **kwargs)\n",
      " |      Perform a string formatting operation, like the built-in\n",
      " |      `str.format(*args, **kwargs)`. Returns a blob object.\n",
      " |  \n",
      " |  index(self, sub, start=0, end=9223372036854775807)\n",
      " |      Like blob.find() but raise ValueError when the substring\n",
      " |      is not found.\n",
      " |  \n",
      " |  join(self, iterable)\n",
      " |      Behaves like the built-in `str.join(iterable)` method, except\n",
      " |      returns a blob object.\n",
      " |      \n",
      " |      Returns a blob which is the concatenation of the strings or blobs\n",
      " |      in the iterable.\n",
      " |  \n",
      " |  lower(self)\n",
      " |      Like str.lower(), returns new object with all lower-cased characters.\n",
      " |  \n",
      " |  replace(self, old, new, count=9223372036854775807)\n",
      " |      Return a new blob object with all the occurence of `old` replaced\n",
      " |      by `new`.\n",
      " |  \n",
      " |  rfind(self, sub, start=0, end=9223372036854775807)\n",
      " |      Behaves like the built-in str.rfind() method. Returns an integer,\n",
      " |      the index of he last (right-most) occurence of the substring argument\n",
      " |      sub in the sub-sequence given by [start:end].\n",
      " |  \n",
      " |  rindex(self, sub, start=0, end=9223372036854775807)\n",
      " |      Like blob.rfind() but raise ValueError when substring is not\n",
      " |      found.\n",
      " |  \n",
      " |  starts_with = startswith(self, prefix, start=0, end=9223372036854775807)\n",
      " |  \n",
      " |  startswith(self, prefix, start=0, end=9223372036854775807)\n",
      " |      Returns True if the blob starts with the given prefix.\n",
      " |  \n",
      " |  strip(self, chars=None)\n",
      " |      Behaves like the built-in str.strip([chars]) method. Returns\n",
      " |      an object with leading and trailing whitespace removed.\n",
      " |  \n",
      " |  title(self)\n",
      " |      Returns a blob object with the text in title-case.\n",
      " |  \n",
      " |  upper(self)\n",
      " |      Like str.upper(), returns new object with all upper-cased characters.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from textblob.mixins.StringlikeMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from textblob.mixins.ComparableMixin:\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __ge__(self, other)\n",
      " |      Return self>=value.\n",
      " |  \n",
      " |  __gt__(self, other)\n",
      " |      Return self>value.\n",
      " |  \n",
      " |  __le__(self, other)\n",
      " |      Return self<=value.\n",
      " |  \n",
      " |  __lt__(self, other)\n",
      " |      Return self<value.\n",
      " |  \n",
      " |  __ne__(self, other)\n",
      " |      Return self!=value.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# this shows the various functions that can be performed using textblob\n",
    "help(tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hi', 'NN'),\n",
       " ('please', 'VB'),\n",
       " ('like', 'IN'),\n",
       " ('this', 'DT'),\n",
       " ('video', 'NN')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# POS tags\n",
    "tb.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList([])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting the noun phrases\n",
    "tb.noun_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.0, subjectivity=0.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = blob(\"I hate you. You are a bitch.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=-0.8, subjectivity=0.9)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = blob(\"I love this channel. Very happy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.75, subjectivity=0.8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyaudio in f:\\anaconda3\\lib\\site-packages (0.2.11)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = sr.Recognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say Something...\n"
     ]
    }
   ],
   "source": [
    "with sr.Microphone() as source:\n",
    "    print(\"Say Something...\")\n",
    "    audio = r.listen(source, timeout = 2)\n",
    "    try:\n",
    "        text = r.recognize_google(audio)\n",
    "        tb = blob(text)\n",
    "        print(text)\n",
    "        print(tb.sentiment)\n",
    "    except:\n",
    "        print(\"Sorry... Please Try Again\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
